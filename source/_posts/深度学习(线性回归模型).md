---
title: 深度学习(线性回归模型)
categories: 阅读
date: 2024-10-10 10:20:45
tags: 人工智能
---

# 深度学习(线性回归模型)

## 监督学习

**定义：**

​	映射 x -> y的算法（input ->  output）

提供输入（source）和正确的输出（labels） 通过定义的算法 训练，让他变成仅接受输入就能预测或猜测出输出 



**回归和分类是深度学习中的两大主要任务方向。**

1. **回归**：如前所述，回归任务主要用于预测连续的数值。它会输出一个实数，常见的应用包括房价预测、温度预测、销售额预测等。回归分析帮助我们理解输入变量与输出变量之间的关系。
2. **分类**：分类任务用于将输入数据分配到离散的类别中。常见的应用包括图像分类（例如，识别图片中的物体）、文本分类（例如，垃圾邮件检测）、情感分析等。在分类任务中，模型的输出通常是一个类别标签或者每个类别的概率。

这两种任务在深度学习模型的设计、损失函数的选择及评估指标上有显著的区别。回归一般使用均方误差（MSE）作为损失函数，而分类则常用交叉熵损失。对于评估，回归常用均方根误差（RMSE）等指标，而分类则多用准确率、精确率、召回率等。

<!--more-->

## 非监督学习

非监督学习是一种在没有标签（labels）和明确目标输出的情况下进行学习的机器学习方法。其主要目标是识别和理解数据中的潜在模式、相似性或分组关系。以下是非监督学习的一些关键概念和应用领域：

- **聚类**：聚类算法用于将相似的数据点分组。在市场营销中，可以通过聚类分析划分用户群体，以便准确制定营销策略。此外，在自然语言处理领域，可以将具有相似主题的文章进行分组。
- **异常检测**：非监督学习可用于识别数据中的异常行为或异常点。例如，在网络安全领域，算法可以检测到与正常模式不符的网络活动，从而识别潜在的安全威胁。在金融领域，可以发现异常交易活动，帮助预防欺诈。
- **降维**：降维技术用于将高维数据投影到低维空间，以便于可视化和进一步分析。主成分分析（PCA）和t-SNE是常用的降维技术，它们能够帮助研究者简化数据，同时保留大部分重要信息，使得数据更易于理解。

非监督学习在处理未经标注的数据时具有广泛应用，可以发现数据中的新模式，并揭示潜在的结构，为后续的分析和决策提供支持。



# 线性回归模型

**linear regression**

## 模型Model

形如
$$
f_{w,b}（x） = wx + b
$$
 的线性直线



## 模型的参数 （parameners）

w,b 

模型的参数指 可以在训练期间调整以改进模型的变量 ， 别名权重、系数



## 成本函数

别名 ： 代价函数

为了找到更贴近的w和b，我们将构造一个**成本函数**

**平方误差成本函数**
$$
J(w,b) = \frac{1}{2m} \sum_{i=1}^{m} \left( f_{w,b}(x^{(i)}) - y^{(i)} \right)^2
$$


## 目标

线性回归会尝试找到w，b的值，并尽可能让w，b最小即
$$
minmize J(w,b)
$$

## 梯度下降

梯度下降算法是从一个初始参数（如权重 *w* 和偏置 *b*）开始，通过迭代不断调整这些参数来最小化损失函数。然而，不同的初始参数可能导致梯度下降收敛到不同的局部最小值，尤其是在损失函数具有多个极小值的情况下。

### 实现梯度下降

线性回归中公式如下，注意这里的等于号是 **赋值** 而非 相等
$$
w = w - \alpha \frac{d}{dw} J(w, b)
$$

$$
b = b - \alpha \frac{d}{db} J(w, b)
$$

求导后结果
$$
w = \frac{1}{m} \sum_{i=1}^{m} \left( f_{w,b}(x^{(i)}) - y^{(i)} \right)x^{(i)}
$$

$$
b = \frac{1}{m} \sum_{i=1}^{m} \left( f_{w,b}(x^{(i)}) - y^{(i)} \right)
$$

α：学习率（learning rate），通常是一个0~1之间的小正数

- alpha越大，梯度下降越激烈
- 太小走的慢，太大不一定能到最小值，卡在山谷的两边，甚至发散，离目标值越来越远

​	

w,b两个应该**同步更新**



导数向：表示了损失函数 在参数空间中的变化率和方向

- 正值：如果某个参数的导数为正，说明增加该参数会导致损失增加。这意味着我们应该减少这个参数的值，以期降低损失。
- 负值：如果导数为负，说明增加该参数会导致损失减少。在这种情况下，我们应该增加这个参数的值。
- 零值：当导数为零时，表示此处可能是一个最优解（局部最低点或鞍点），因为在这一点上，损失函数不再变化。



## 构建模型

**test.py**

```
import numpy as np  
# NumPy（Numerical Python）是一个用于 Python 的开源库，广泛用于科学计算和数据分析
# 读取数据  

filedata = np.loadtxt('test.txt') 
Areas = filedata[:, 0]  # 面积  
Prices = filedata[:, 1]  # 房价  

# 数据归一化  
#np.mean() : 用于计算输入数组的均值（平均值）ac
#np.std() : 用于计算输入数组的标准差。标准差是衡量数据分布的离散程度的指标，它表示数据与均值的偏离程度。
Areas = (Areas - np.mean(Areas)) / np.std(Areas)  
Prices = (Prices - np.mean(Prices)) / np.std(Prices)  

#模型 f(x) = wx+b
class LinerModle:
    def __init__(self):
        self.w = 0
        self.b = 0

    def run(self , areas):
        return self.w * areas + self.b

    def train(self , areas, prices, alpha = 0.001 , it = 500):
        m = len(prices)
        print(f"数据集数量为{m}")

        for i in range(it):
            #costs = f_{w,b}(x) - y
            costs = self.run(areas) - prices

            #np.dot() 是 NumPy 中的一个函数，用于计算两个数组的点积（也称为内积）
            #a 点积 b = a1*b1 + .. + ai*bi + .. + an*bn
            # w = 1/m * sum((costs)*x)
            tmp_w = (1/m)*np.dot(costs,areas)
            # b = 1/m * sum(costs)
            tmp_b = (1/m)*np.sum(costs)
            #确保同步更新
            self.w -= alpha * tmp_w
            self.b -= alpha * tmp_b
            #if i % 100 == 0 :
             #   print(f"第{i}轮训练, w: {model.w} , b: {model.b}")


model = LinerModle()
model.train(Areas,Prices)

test_area = input("请输入你的房屋面积(上海黄埔):")
test_area = float(test_area)

# 归一化输入  
test_area_normalized = (test_area - np.mean(filedata[:, 0])) / np.std(filedata[:, 0])  
predicted_price_normalized = model.run(test_area_normalized)  

# 反归一化输出  
predicted_price = predicted_price_normalized * np.std(filedata[:, 1]) + np.mean(filedata[:, 1]) 

print(f"预测房价(面积{test_area}平方米) : {predicted_price} 万")
#输出经过模型处理的情况

```



**创建pytroch模型**

```
import numpy as np  
import torch  
import torch.nn as nn  
import torch.optim as optim  

# 读取数据  
filedata = np.loadtxt('test.txt', dtype=float)  
Areas = filedata[:, 0]  # 面积  
Prices = filedata[:, 1]  # 房价  

# 数据归一化  
Areas = (Areas - np.mean(Areas)) / np.std(Areas)  
Prices = (Prices - np.mean(Prices)) / np.std(Prices)  

# 定义线性回归模型  
class LinearModel(nn.Module):  
    def __init__(self):  
        super(LinearModel, self).__init__()  
        self.linear = nn.Linear(1, 1)  # 输入一个特征，输出一个目标值  

    def forward(self, x):  
        return self.linear(x)  

# 创建模型实例  
model = LinearModel()  

# 准备输入数据  
areas_tensor = torch.from_numpy(Areas).float().view(-1, 1)  # 转换为 PyTorch 张量  
prices_tensor = torch.from_numpy(Prices).float().view(-1, 1)  # 转换为 PyTorch 张量  

# 定义损失函数和优化器  
criterion = nn.MSELoss()  # 均方误差损失  
optimizer = optim.SGD(model.parameters(), lr=0.001)  # 随机梯度下降优化器  

# 训练模型  
epochs = 500  
for epoch in range(epochs):  
    model.train()  # 将模型设置为训练模式  

    # 前向传播  
    optimizer.zero_grad()  # 清零梯度  
    outputs = model(areas_tensor)  # 输出结果  
    loss = criterion(outputs, prices_tensor)  # 计算损失  

    # 反向传播和优化  
    loss.backward()  # 反向传播  
    optimizer.step()  # 更新参数  

    # 每100个epoch打印一次损失  
    if epoch % 100 == 0:  
        print(f"Epoch {epoch}, Loss: {loss.item()}")  

# 保存模型为.pt  
torch.save(model.state_dict(), 'linear_regression_model.pt')  

# 转换为 ONNX 格式  
dummy_input = torch.tensor([[0.0]], dtype=torch.float32)  # 模型输入的占位符  
torch.onnx.export(model, dummy_input, "linear_regression_model.onnx", verbose=True)  

print("模型已保存为 'linear_regression_model.pt' 和 'linear_regression_model.onnx'")
```



**测试pt模型正确性**

testpt.py

```
import sys  
import numpy as np  
import torch  
import torch.nn as nn  

# 定义线性回归模型  
class LinearModel(nn.Module):  
    def __init__(self):  
        super(LinearModel, self).__init__()  
        self.linear = nn.Linear(1, 1)  # 输入一个特征，输出一个目标值  

    def forward(self, x):  
        return self.linear(x)  

def load_model(model_path):  
    """  
    加载模型  
    """  
    model = LinearModel()  
    model.load_state_dict(torch.load(model_path))  
    model.eval()  # 设置为评估模式  
    return model  

def predict_price(model, area, filedata):  
    """  
    预测房价  
    """  
    # 归一化输入  
    areas = filedata[:, 0]  
    area_normalized = (area - np.mean(areas)) / np.std(areas)  

    # 将输入转换为 PyTorch 的张量  
    area_tensor = torch.tensor([[area_normalized]], dtype=torch.float32)  

    # 进行预测  
    with torch.no_grad():  
        predicted_price_normalized = model(area_tensor)  

    # 反归一化输出  
    prices = filedata[:, 1]  
    predicted_price = predicted_price_normalized.item() * np.std(prices) + np.mean(prices)  
    
    return predicted_price  

if __name__ == "__main__":  
    if len(sys.argv) != 3:  
        print("用法: python predict.py <model_path> <area>")  
        sys.exit(1)  

    model_path = sys.argv[1]  
    area = float(sys.argv[2])  

    # 读取数据  
    filedata = np.loadtxt('test.txt')  

    # 加载模型  
    model = load_model(model_path)  

    # 进行预测  
    price = predict_price(model, area, filedata)  

    # 打印结果  
    print(f"预测房价(面积 {area} 平方米): {price} 万")
```



**测试onnx模型正确性**

```
#include <iostream>  
#include <vector>  
#include <string>  
#include <opencv2/opencv.hpp>  
#include <opencv2/dnn/dnn.hpp>  

using cv::Mat;  
using std::vector;  
using std::string;  
using std::cout;  
using std::endl;  

// 从您计算的结果中填入均值和标准差  
const float mean_area = 113.7988f; // 房屋面积均值  
const float std_area = 45.4836f;   // 房屋面积标准差  
const float mean_price = 1176.76f; // 房价均值  
const float std_price = 1118.3278f; // 房价标准差 

int main(int argc, char* argv[]) {  
    if (argc != 2) {  
        cout << "Usage: " << argv[0] << " <area>" << endl;  
        return -1;  
    }  

    // 解析输入参数  
    float area = std::stof(argv[1]);  

    // 读取 ONNX 模型  
    cv::dnn::Net net = cv::dnn::readNetFromONNX("linear_regression_model.onnx");   

    // 归一化输入数据  
    float normalized_area = (area - mean_area) / std_area;  

    // 创建输入张量  
    Mat inputBlob = Mat(1, 1, CV_32F, normalized_area);  
    net.setInput(inputBlob);  

    // 执行推理  
    Mat output = net.forward();  

    // 反归一化输出  
    float predicted_price_normalized = output.at<float>(0, 0);  
    float predicted_price = predicted_price_normalized * std_price + mean_price;  

    // 输出结果  
    cout << "预测房价(面积 " << area << " 平方米): " << predicted_price << " 万" << endl;  

    return 0;  
}
```

追加：

**计算均差和标准差**

tmp.py

```
import numpy as np  

# 读取数据  
data = np.loadtxt('test.txt')  

# 计算均值和标准差  
mean_area = np.mean(data[:, 0])  # 房屋面积的均值  
std_area = np.std(data[:, 0])    # 房屋面积的标准差  
mean_price = np.mean(data[:, 1]) # 房价的均值  
std_price = np.std(data[:, 1])   # 房价的标准差  

print("Mean Area:", mean_area)  
print("Std Area:", std_area)  
print("Mean Price:", mean_price)  
print("Std Price:", std_price)
```

